{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DataSet_Corn_Cepea.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMkKi56HUC6LkGUs/ltyRoT",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rodrigonevest/projetophyton/blob/master/DataSet_Corn_Cepea.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xA7c3fdd-aVr",
        "outputId": "422cc78b-6018-4e9f-c5ad-b7e114b56f36"
      },
      "source": [
        "import urllib3\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "import numpy as np\n",
        " \n",
        " \n",
        "nltk.download('book')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'book'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/abc.zip.\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/brown.zip.\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/chat80.zip.\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2000.zip.\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/conll2002.zip.\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/dependency_treebank.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ieer.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/book_grammars.zip.\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/city_database.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection book\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1cVy8qVN4x9w"
      },
      "source": [
        "# Fazendo Web Crawler\n",
        "|| Extraindo a Data, Link, Machete e Noticias \n",
        "| Site : http://soybeansandcorn.com\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zScauQr5SBO"
      },
      "source": [
        " \n",
        "def BuscaTexto(pagina):\n",
        "  \n",
        "  urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
        " \n",
        "  #Criando o dataframe para salvar os dados\n",
        "  df = pd.DataFrame(index=['Date','Link','Headlines','News'])#,'Cbot_corn','CepeaR$_corn','CepeaU$','Rótulo'\"\"\",'Pais'\"\"\"])  \n",
        " \n",
        "  http = urllib3.PoolManager()\n",
        " \n",
        "  try:\n",
        "    dados_paginas = http.request('GET',pagina)\n",
        " \n",
        "  except HTTPError as e:\n",
        "    print(e)\n",
        "  except URLError:\n",
        "    print(\"Server down or incorrect domain\")  \n",
        "   # Pegando os dados do html da pagina\n",
        "  index = BeautifulSoup(dados_paginas.data,'lxml')\n",
        " \n",
        "  #Procurando as tag \"a\" dentro da \"div\"\n",
        "  links = index.find(\"div\",{\"id\":\"content\"})\n",
        "  links = links.find_all('a')\n",
        "  #print(links)\n",
        "  \n",
        "  cont = 0\n",
        "  base = pagina.split('/News')[0]\n",
        " \n",
        "  #Percorrendo os link e salvando seu href(os links)    \n",
        "  for link in links:    \n",
        "    if cont == range(len(base)):        \n",
        "      break;\n",
        " \n",
        "    else:\n",
        "      cont +=1   \n",
        "        \n",
        "    aux = str(link.get('href'))\n",
        "    url = base + '/' + aux\n",
        " \n",
        "    try:\n",
        "      dados = http.request('GET',url)\n",
        "    except:\n",
        "     print(\"Pagina nao encontrada\" )    \n",
        " \n",
        "    #Pegando os dados do html do link acessado\n",
        "    news = BeautifulSoup(dados.data,'lxml')\n",
        " \n",
        "    #Pegando o conteúdo da Manchete\n",
        "    conteudo = news.find(\"div\",{\"id\": \"content\"})       \n",
        "           \n",
        "    #Pegando o conteudo das noticias\n",
        "    noticias = news.find(\"div\",{\"id\": \"content\"}) \n",
        "    noticia = news.find(\"div\",{\"id\": \"content\"})\n",
        "         \n",
        "    if noticias != None:\n",
        "      noticias = [y.get_text(strip=True) for y in news.find_all('p')]      \n",
        "      noticias = str(noticias)\n",
        "      noticias = noticias.replace(\"['\",'')\n",
        "      noticias = noticias.replace(\"']\",'')\n",
        "      noticias = noticias.replace('[\"','')\n",
        "      noticias = noticias.replace('\"]','')\n",
        "      noticias = noticias.replace(\"', '\",'') \n",
        " \n",
        "      conteudo = [x.get_text(strip=True) for x in news.find_all('h3')]\n",
        "      conteudo = str(conteudo)\n",
        "      conteudo = conteudo.replace(\"['\",'')\n",
        "      conteudo = conteudo.replace(\"']\",'')\n",
        "      conteudo = conteudo.replace('[\"','')\n",
        "      conteudo = conteudo.replace('\"]','')\n",
        "      conteudo = conteudo.replace(\"', '\",'')\n",
        "       \n",
        "      data = news.find({\"h5\"}).get_text(strip=True)\n",
        "      if noticia != None:    \n",
        "        noticia = [j for j in noticia.find_all('li',text=True)]      \n",
        "        noticia = str(noticia)\n",
        "        noticia = noticia.replace(\"['\",'')\n",
        "        noticia = noticia.replace(\"']\",'')\n",
        "        noticia = noticia.replace('[\"','')\n",
        "        noticia = noticia.replace('\"]','')\n",
        "        noticia = noticia.replace(\"', '\",'')\n",
        "        noticia = noticia.replace('<\"','')\n",
        "        noticia = noticia.replace('\">','') \n",
        "        noticia = noticia.replace('\"\\n','')\n",
        "        noticia = re.sub('[\\n,\\t,<li>,/]','',noticia)\n",
        " \n",
        "      data = news.find({\"h5\"}).get_text(strip=True)\n",
        " \n",
        "      df = df.append({'Date': data,\n",
        "                        'Link': url ,\n",
        "                        'Headlines' : conteudo,\n",
        "                         'News': noticias + noticia,\n",
        "                          }, #'Pais': j},                                   \n",
        "                          ignore_index=True)      \n",
        "  \n",
        "  return df"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "W847WoXI7SGG",
        "outputId": "fe6a5cac-b6c5-4e64-cca0-277dcb1d0c6e"
      },
      "source": [
        "link2 = 'http://soybeansandcorn.com/News'\n",
        "\n",
        "df = BuscaTexto(link2)\n",
        "df.dropna(inplace=True)\n",
        "df['Date'] = pd.to_datetime(df['Date'],errors='coerce')\n",
        "df.dropna(subset=['Date'],inplace=True)\n",
        "\n",
        "\n",
        "df.head(-1)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Headlines</th>\n",
              "      <th>Link</th>\n",
              "      <th>News</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-05-14</td>\n",
              "      <td>Farmers in Mato Grosso have Sold 83% of their ...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May14_21-Farme...</td>\n",
              "      <td>According to the Mato Grosso Institute of Agri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2021-05-13</td>\n",
              "      <td>Conab Lowers Brazil Corn Production 2.5 mt to ...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May13_21-Conab...</td>\n",
              "      <td>In their May Crop Report, Conab lowered the 20...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>2021-05-13</td>\n",
              "      <td>Sugarcane Harvesting in Brazil during First Mo...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May13_21-Sugar...</td>\n",
              "      <td>The Brazilian sugarcane production year goes f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>2021-05-12</td>\n",
              "      <td>2020/21 Brazil Safrinha Corn Production Contin...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May12_21-20202...</td>\n",
              "      <td>The combination of historically late planting ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2021-05-12</td>\n",
              "      <td>2020/21 Argentina Corn 22.7% Harvested vs. 32....</td>\n",
              "      <td>http://soybeansandcorn.com/news/May12_21-20202...</td>\n",
              "      <td>The later planted corn in Argentina benefited ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2750</th>\n",
              "      <td>2014-01-08</td>\n",
              "      <td>Thousands of Additional Trucks Expected on Bra...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan8_14-Thousd...</td>\n",
              "      <td>The combination of a record large soybean crop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2751</th>\n",
              "      <td>2014-01-07</td>\n",
              "      <td>Brazilian Farmers Advised to stay Vigilant abo...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan7_14-Brazil...</td>\n",
              "      <td>As farmers in Mato Grosso start to harvest som...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2752</th>\n",
              "      <td>2014-01-07</td>\n",
              "      <td>Livestock Producers in Brazil Fear Diversion o...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan7_14-Livest...</td>\n",
              "      <td>Poultry and hog producers in southern Brazil a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2753</th>\n",
              "      <td>2014-01-06</td>\n",
              "      <td>Capacity Expands at Latin America's Largest Gr...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan6_14-Capaci...</td>\n",
              "      <td>America Latina Logistica (ALL) recently inaugu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2754</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>Good Yield Reports from Early Soybean Harvest ...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan3_14-Good-Y...</td>\n",
              "      <td>Farmers in Mato Grosso have started to harvest...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2742 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date  ...                                               News\n",
              "4    2021-05-14  ...  According to the Mato Grosso Institute of Agri...\n",
              "5    2021-05-13  ...  In their May Crop Report, Conab lowered the 20...\n",
              "6    2021-05-13  ...  The Brazilian sugarcane production year goes f...\n",
              "7    2021-05-12  ...  The combination of historically late planting ...\n",
              "8    2021-05-12  ...  The later planted corn in Argentina benefited ...\n",
              "...         ...  ...                                                ...\n",
              "2750 2014-01-08  ...  The combination of a record large soybean crop...\n",
              "2751 2014-01-07  ...  As farmers in Mato Grosso start to harvest som...\n",
              "2752 2014-01-07  ...  Poultry and hog producers in southern Brazil a...\n",
              "2753 2014-01-06  ...  America Latina Logistica (ALL) recently inaugu...\n",
              "2754 2014-01-03  ...  Farmers in Mato Grosso have started to harvest...\n",
              "\n",
              "[2742 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06CcbiVR7V5O",
        "outputId": "d2eb8ddc-23d8-4f15-ba7a-6db4e4d06ecc"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Date         0\n",
              "Headlines    0\n",
              "Link         0\n",
              "News         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pf-GQMRY7Yri"
      },
      "source": [
        "df.to_csv('Crawler_Corn_Soybeans.csv',index=False)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4BWS_GXtsls"
      },
      "source": [
        "# Criando um DataFrame com os valores do Cbot, Cepea em real e Cepea  em dolar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "214H7axMaUaE",
        "outputId": "16cb18a2-8b95-4d2a-f220-4503e1d9a7f5"
      },
      "source": [
        "!pip install OleFileIO_PL\n",
        "!pip install scrapy\n",
        "\n",
        "import scrapy\n",
        "from scrapy.loader import ItemLoader\n",
        "import requests\n",
        "import OleFileIO_PL"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting OleFileIO_PL\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/05/f124ecb536ae2090891d3bcb6a65facd1358f4fd10422c1354357687e8dc/OleFileIO_PL-0.42.1.zip (120kB)\n",
            "\r\u001b[K     |██▊                             | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 20kB 17.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 30kB 14.0MB/s eta 0:00:01\r\u001b[K     |███████████                     | 40kB 12.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 51kB 7.3MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 61kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 81kB 8.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 92kB 8.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 102kB 7.0MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 112kB 7.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 122kB 7.0MB/s \n",
            "\u001b[33m  WARNING: Generating metadata for package OleFileIO-PL produced metadata for project name olefile. Fix your #egg=OleFileIO-PL fragments.\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: olefile, olefile\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for olefile: filename=olefile-0.42.1-cp37-none-any.whl size=111385 sha256=4e1edb26bb9cbd41e6f9c03002d6a6e5de2b1888b76a4172cfac3cf9304fd426\n",
            "  Stored in directory: /root/.cache/pip/wheels/7f/a6/17/86b00b33e526659bb900323f8563ccff99193af07457a31dd9\n",
            "  Building wheel for olefile (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for olefile\u001b[0m\n",
            "\u001b[?25h  Running setup.py clean for olefile\n",
            "\u001b[31m  ERROR: Failed cleaning build dir for olefile\u001b[0m\n",
            "Successfully built olefile\n",
            "Failed to build olefile\n",
            "Installing collected packages: olefile\n",
            "Successfully installed olefile-0.42.1\n",
            "Collecting scrapy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/68/0e84466f83ed7d57b0da402bef1bb33a030224a64523a744de2abb8595f4/Scrapy-2.5.0-py2.py3-none-any.whl (254kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 7.6MB/s \n",
            "\u001b[?25hCollecting cssselect>=0.9.1\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting service-identity>=16.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/93/5a/5e93f280ec7be676b5a57f305350f439d31ced168bca04e6ffa64b575664/service_identity-21.1.0-py2.py3-none-any.whl\n",
            "Collecting Twisted[http2]>=17.9.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/16/3eb9c66a7bfb5220c7bcbaaac33d359fe8a157b028959cd210983749b2e0/Twisted-21.2.0-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 41.0MB/s \n",
            "\u001b[?25hCollecting queuelib>=1.4.2\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/30/0670f4b7a4eef6cf453336c5661eff41da2650e5f143c039b50e033732bd/queuelib-1.6.1-py2.py3-none-any.whl\n",
            "Collecting w3lib>=1.17.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/59/b6b14521090e7f42669cafdb84b0ab89301a42f1f1a82fcf5856661ea3a7/w3lib-1.22.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=3.5.0; platform_python_implementation == \"CPython\" in /usr/local/lib/python3.7/dist-packages (from scrapy) (4.2.6)\n",
            "Collecting PyDispatcher>=2.0.5; platform_python_implementation == \"CPython\"\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/37/39aca520918ce1935bea9c356bcbb7ed7e52ad4e31bff9b943dfc8e7115b/PyDispatcher-2.0.5.tar.gz\n",
            "Collecting pyOpenSSL>=16.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/5e/06351ede29fd4899782ad335c2e02f1f862a887c20a3541f17c3fa1a3525/pyOpenSSL-20.0.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 10.2MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b2/26/7af637e6a7e87258b963f1731c5982fb31cd507f0d90d91836e446955d02/cryptography-3.4.7-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 48.7MB/s \n",
            "\u001b[?25hCollecting protego>=0.1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/6e/bf6d5e4d7cf233b785719aaec2c38f027b9c2ed980a0015ec1a1cced4893/Protego-0.1.16.tar.gz (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 28.1MB/s \n",
            "\u001b[?25hCollecting itemadapter>=0.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/88/83/ab33780fd93278e699561d61862d27343c95d3fe0a0081acd73e8e26a649/itemadapter-0.2.0-py3-none-any.whl\n",
            "Collecting itemloaders>=1.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/2b/eb2ddf7becf834679273a6f79ffdc6fbedf07c5272e2eddf412582143c0e/itemloaders-1.0.4-py3-none-any.whl\n",
            "Collecting parsel>=1.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/23/1e/9b39d64cbab79d4362cdd7be7f5e9623d45c4a53b3f7522cd8210df52d8e/parsel-1.6.0-py2.py3-none-any.whl\n",
            "Collecting h2<4.0,>=3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/25/de/da019bcc539eeab02f6d45836f23858ac467f584bfec7a526ef200242afe/h2-3.2.0-py2.py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.2MB/s \n",
            "\u001b[?25hCollecting zope.interface>=4.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/a7/94e1a92c71436f934cdd2102826fa041c83dcb7d21dd0f1fb1a57f6e0620/zope.interface-5.4.0-cp37-cp37m-manylinux2010_x86_64.whl (251kB)\n",
            "\u001b[K     |████████████████████████████████| 256kB 41.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.4.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (0.2.8)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.7/dist-packages (from service-identity>=16.0.0->scrapy) (21.2.0)\n",
            "Collecting Automat>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/dd/83/5f6f3c1a562674d65efc320257bdc0873ec53147835aeef7762fe7585273/Automat-20.2.0-py2.py3-none-any.whl\n",
            "Collecting constantly>=15.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b9/65/48c1909d0c0aeae6c10213340ce682db01b48ea900a7d9fce7a7910ff318/constantly-15.1.0-py2.py3-none-any.whl\n",
            "Collecting incremental>=16.10.1\n",
            "  Downloading https://files.pythonhosted.org/packages/99/3b/4f80dd10cb716f3a9e22ae88f026d25c47cc3fdf82c2747f3d59c98e4ff1/incremental-21.3.0-py2.py3-none-any.whl\n",
            "Collecting hyperlink>=17.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/aa/8caf6a0a3e62863cbb9dab27135660acba46903b703e224f14f447e57934/hyperlink-21.0.0-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 13.7MB/s \n",
            "\u001b[?25hCollecting priority<2.0,>=1.1.0; extra == \"http2\"\n",
            "  Downloading https://files.pythonhosted.org/packages/de/96/2f4b8da7be255cd41e825c398efd11a6706ff86e66ae198f012204aa2a4f/priority-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->scrapy) (1.14.5)\n",
            "Collecting jmespath>=0.9.5\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting hpack<4,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/cc/e53517f4a1e13f74776ca93271caef378dadec14d71c61c949d759d3db69/hpack-3.0.0-py2.py3-none-any.whl\n",
            "Collecting hyperframe<6,>=5.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/19/0c/bf88182bcb5dce3094e2f3e4fe20db28a9928cb7bd5b08024030e4b140db/hyperframe-5.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from zope.interface>=4.1.3->scrapy) (56.1.0)\n",
            "Requirement already satisfied: idna>=2.5 in /usr/local/lib/python3.7/dist-packages (from hyperlink>=17.1.1->Twisted[http2]>=17.9.0->scrapy) (2.10)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.20)\n",
            "Building wheels for collected packages: PyDispatcher, protego\n",
            "  Building wheel for PyDispatcher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for PyDispatcher: filename=PyDispatcher-2.0.5-cp37-none-any.whl size=11517 sha256=df6aabb848f786bd8b3e3fdd8852f00db4551d07a856d1ad0ed3dc8a6a75a931\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/99/96/cfef6665f9cb1522ee6757ae5955feedf2fe25f1737f91fa7f\n",
            "  Building wheel for protego (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for protego: filename=Protego-0.1.16-cp37-none-any.whl size=7766 sha256=2380b7c05249ea15dfc0923a434400a2601c5d92a09b3779ba459ae7c388196d\n",
            "  Stored in directory: /root/.cache/pip/wheels/51/01/d1/4a2286a976dccd025ba679acacfe37320540df0f2283ecab12\n",
            "Successfully built PyDispatcher protego\n",
            "Installing collected packages: cssselect, cryptography, service-identity, Automat, constantly, zope.interface, incremental, hyperlink, hpack, hyperframe, h2, priority, Twisted, queuelib, w3lib, PyDispatcher, pyOpenSSL, protego, itemadapter, jmespath, parsel, itemloaders, scrapy\n",
            "Successfully installed Automat-20.2.0 PyDispatcher-2.0.5 Twisted-21.2.0 constantly-15.1.0 cryptography-3.4.7 cssselect-1.1.0 h2-3.2.0 hpack-3.0.0 hyperframe-5.2.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.2.0 itemloaders-1.0.4 jmespath-0.10.0 parsel-1.6.0 priority-1.3.0 protego-0.1.16 pyOpenSSL-20.0.1 queuelib-1.6.1 scrapy-2.5.0 service-identity-21.1.0 w3lib-1.22.0 zope.interface-5.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "viKXS1J6CUas",
        "outputId": "7fcbbe14-8974-4a9d-805d-056137ee4043"
      },
      "source": [
        "\n",
        "  \n",
        "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning) \n",
        "\n",
        "http = urllib3.PoolManager()\n",
        "\n",
        "pagina = 'https://www.cepea.esalq.usp.br/br/indicador/milho.aspx'\n",
        " \n",
        "try:\n",
        "  dados_paginas = http.request('GET',pagina)\n",
        " \n",
        "except HTTPError as e:\n",
        "  print(e)\n",
        "except URLError:\n",
        "  print(\"Server down or incorrect domain\")  \n",
        "   # Pegando os dados do html da pagina\n",
        "index = BeautifulSoup(dados_paginas.data,'lxml')\n",
        "\n",
        "  #Procurando as tag \"a\" dentro da \"div\"\n",
        "links = index.find(\"div\",{\"class\":\"imagenet-links-after-table imagenet-col-2 imagenet-pa-l imagenet-bb imagenet-fl\"})\n",
        "links = links.find_all('a')[-1]\n",
        "links = links.get('href')\n",
        "\n",
        "print('\\n\\nClica no link para fazer o download: \\n',links,'\\n\\n')\n",
        "\n",
        " \n",
        "resp = requests.get(links)\n",
        "ole = OleFileIO_PL.OleFileIO(resp.content) \n",
        "\n",
        "cepea = pd.read_excel(ole.openstream('Workbook'),skiprows=3)\n",
        "cepea['Data'] = pd.to_datetime(cepea['Data'],errors='coerce')\n",
        "cepea.rename(columns={'Data':'Date'},inplace=True)\n",
        "\n",
        "cepea.head(-1)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Clica no link para fazer o download: \n",
            " https://www.cepea.esalq.usp.br/br/indicador/series/milho.aspx?id=77 \n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>À vista R$</th>\n",
              "      <th>À vista US$</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2004-02-08</td>\n",
              "      <td>18.24</td>\n",
              "      <td>5.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2004-03-08</td>\n",
              "      <td>18.04</td>\n",
              "      <td>5.91</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2004-04-08</td>\n",
              "      <td>18.02</td>\n",
              "      <td>5.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2004-05-08</td>\n",
              "      <td>18.06</td>\n",
              "      <td>5.89</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2004-06-08</td>\n",
              "      <td>18.13</td>\n",
              "      <td>5.98</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4171</th>\n",
              "      <td>2021-07-05</td>\n",
              "      <td>101.56</td>\n",
              "      <td>19.45</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4172</th>\n",
              "      <td>2021-10-05</td>\n",
              "      <td>101.23</td>\n",
              "      <td>19.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4173</th>\n",
              "      <td>2021-11-05</td>\n",
              "      <td>101.40</td>\n",
              "      <td>19.41</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4174</th>\n",
              "      <td>2021-12-05</td>\n",
              "      <td>102.39</td>\n",
              "      <td>19.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4175</th>\n",
              "      <td>2021-05-13</td>\n",
              "      <td>101.79</td>\n",
              "      <td>19.21</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4176 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date  À vista R$  À vista US$\n",
              "0    2004-02-08       18.24         5.98\n",
              "1    2004-03-08       18.04         5.91\n",
              "2    2004-04-08       18.02         5.90\n",
              "3    2004-05-08       18.06         5.89\n",
              "4    2004-06-08       18.13         5.98\n",
              "...         ...         ...          ...\n",
              "4171 2021-07-05      101.56        19.45\n",
              "4172 2021-10-05      101.23        19.35\n",
              "4173 2021-11-05      101.40        19.41\n",
              "4174 2021-12-05      102.39        19.33\n",
              "4175 2021-05-13      101.79        19.21\n",
              "\n",
              "[4176 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tjofj29RjiuE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2f9dd4d-760e-4b13-9d08-0785b25ae198"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "fDT9qST0kPl2",
        "outputId": "b457a2cc-141b-4910-a032-17b8ff4462b7"
      },
      "source": [
        "cbot = pd.read_csv('/content/drive/My Drive/dataset/cobot.csv', parse_dates=True, sep=';')\n",
        "cbot.rename(columns={'date':'Date'},inplace=True)\n",
        "cbot['Date'] = pd.to_datetime(cbot['Date'],errors='coerce')\n",
        "cbot.dropna(inplace=True)\n",
        "cbot.head()\n",
        "\n",
        "cbot.head(-1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1959-07-01</td>\n",
              "      <td>1.1770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1959-07-02</td>\n",
              "      <td>1.1760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1959-07-06</td>\n",
              "      <td>1.1710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1959-07-07</td>\n",
              "      <td>1.1710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1959-07-08</td>\n",
              "      <td>1.1700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15562</th>\n",
              "      <td>2021-04-09</td>\n",
              "      <td>5.7725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15563</th>\n",
              "      <td>2021-04-12</td>\n",
              "      <td>5.6900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15564</th>\n",
              "      <td>2021-04-13</td>\n",
              "      <td>5.8000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15565</th>\n",
              "      <td>2021-04-14</td>\n",
              "      <td>5.9400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15566</th>\n",
              "      <td>2021-04-15</td>\n",
              "      <td>5.9000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>15567 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date   value\n",
              "0     1959-07-01  1.1770\n",
              "1     1959-07-02  1.1760\n",
              "2     1959-07-06  1.1710\n",
              "3     1959-07-07  1.1710\n",
              "4     1959-07-08  1.1700\n",
              "...          ...     ...\n",
              "15562 2021-04-09  5.7725\n",
              "15563 2021-04-12  5.6900\n",
              "15564 2021-04-13  5.8000\n",
              "15565 2021-04-14  5.9400\n",
              "15566 2021-04-15  5.9000\n",
              "\n",
              "[15567 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "rzlLL4HzzyAR",
        "outputId": "063053cf-f310-49b3-cfa8-abf9dc78806a"
      },
      "source": [
        "dataset = pd.merge(df.reset_index(drop= True),cepea,  on='Date', how='left')\n",
        "dataset.rename(columns={'À vista R$':'Cepea_R$'},inplace=True)\n",
        "dataset.rename(columns={'À vista US$':'Cepea_US$'},inplace=True)\n",
        "\n",
        "dataset.head(-1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Headlines</th>\n",
              "      <th>Link</th>\n",
              "      <th>News</th>\n",
              "      <th>Cepea_R$</th>\n",
              "      <th>Cepea_US$</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2021-05-14</td>\n",
              "      <td>Farmers in Mato Grosso have Sold 83% of their ...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May14_21-Farme...</td>\n",
              "      <td>According to the Mato Grosso Institute of Agri...</td>\n",
              "      <td>101.34</td>\n",
              "      <td>19.23</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2021-05-13</td>\n",
              "      <td>Conab Lowers Brazil Corn Production 2.5 mt to ...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May13_21-Conab...</td>\n",
              "      <td>In their May Crop Report, Conab lowered the 20...</td>\n",
              "      <td>101.79</td>\n",
              "      <td>19.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2021-05-13</td>\n",
              "      <td>Sugarcane Harvesting in Brazil during First Mo...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May13_21-Sugar...</td>\n",
              "      <td>The Brazilian sugarcane production year goes f...</td>\n",
              "      <td>101.79</td>\n",
              "      <td>19.21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2021-05-12</td>\n",
              "      <td>2020/21 Brazil Safrinha Corn Production Contin...</td>\n",
              "      <td>http://soybeansandcorn.com/news/May12_21-20202...</td>\n",
              "      <td>The combination of historically late planting ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2021-05-12</td>\n",
              "      <td>2020/21 Argentina Corn 22.7% Harvested vs. 32....</td>\n",
              "      <td>http://soybeansandcorn.com/news/May12_21-20202...</td>\n",
              "      <td>The later planted corn in Argentina benefited ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2737</th>\n",
              "      <td>2014-01-08</td>\n",
              "      <td>Thousands of Additional Trucks Expected on Bra...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan8_14-Thousd...</td>\n",
              "      <td>The combination of a record large soybean crop...</td>\n",
              "      <td>22.93</td>\n",
              "      <td>10.14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2738</th>\n",
              "      <td>2014-01-07</td>\n",
              "      <td>Brazilian Farmers Advised to stay Vigilant abo...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan7_14-Brazil...</td>\n",
              "      <td>As farmers in Mato Grosso start to harvest som...</td>\n",
              "      <td>24.46</td>\n",
              "      <td>11.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2739</th>\n",
              "      <td>2014-01-07</td>\n",
              "      <td>Livestock Producers in Brazil Fear Diversion o...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan7_14-Livest...</td>\n",
              "      <td>Poultry and hog producers in southern Brazil a...</td>\n",
              "      <td>24.46</td>\n",
              "      <td>11.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2740</th>\n",
              "      <td>2014-01-06</td>\n",
              "      <td>Capacity Expands at Latin America's Largest Gr...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan6_14-Capaci...</td>\n",
              "      <td>America Latina Logistica (ALL) recently inaugu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2741</th>\n",
              "      <td>2014-01-03</td>\n",
              "      <td>Good Yield Reports from Early Soybean Harvest ...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan3_14-Good-Y...</td>\n",
              "      <td>Farmers in Mato Grosso have started to harvest...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2742 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date  ... Cepea_US$\n",
              "0    2021-05-14  ...     19.23\n",
              "1    2021-05-13  ...     19.21\n",
              "2    2021-05-13  ...     19.21\n",
              "3    2021-05-12  ...       NaN\n",
              "4    2021-05-12  ...       NaN\n",
              "...         ...  ...       ...\n",
              "2737 2014-01-08  ...     10.14\n",
              "2738 2014-01-07  ...     11.09\n",
              "2739 2014-01-07  ...     11.09\n",
              "2740 2014-01-06  ...       NaN\n",
              "2741 2014-01-03  ...       NaN\n",
              "\n",
              "[2742 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "Klqphppoq-Wc",
        "outputId": "24e22f20-7b53-4856-b85a-0af15277d756"
      },
      "source": [
        "dados = pd.merge(dataset.reset_index(drop=True),cbot, on='Date', how='left')\n",
        "dados.rename(columns={'value':'Cbot_US$'},inplace=True)\n",
        "dados.dropna(inplace=True)\n",
        "\n",
        "\n",
        "dados.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Headlines</th>\n",
              "      <th>Link</th>\n",
              "      <th>News</th>\n",
              "      <th>Cepea_R$</th>\n",
              "      <th>Cepea_US$</th>\n",
              "      <th>Cbot_US$</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2021-04-16</td>\n",
              "      <td>Rating of Safrinha Corn in Parana Declines due...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr16_21-Ratin...</td>\n",
              "      <td>In their latest assessment of the safrinha cor...</td>\n",
              "      <td>97.88</td>\n",
              "      <td>17.52</td>\n",
              "      <td>5.855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2021-04-15</td>\n",
              "      <td>Corn-Based Ethanol Accounts for 9% of Brazil's...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr15_21-Corn-...</td>\n",
              "      <td>The production of ethanol from corn continues ...</td>\n",
              "      <td>97.64</td>\n",
              "      <td>17.36</td>\n",
              "      <td>5.900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2021-04-15</td>\n",
              "      <td>Port of Paranagua Embarks Record Large Soybean...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr15_21-Port-...</td>\n",
              "      <td>The Port of Paranagua in southern Brazil conti...</td>\n",
              "      <td>97.64</td>\n",
              "      <td>17.36</td>\n",
              "      <td>5.900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2021-04-14</td>\n",
              "      <td>IMEA Lowers Mato Grosso's Safrinha Corn Yield</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr14_21-IMEA-...</td>\n",
              "      <td>After the completion of the safrinha corn plan...</td>\n",
              "      <td>96.92</td>\n",
              "      <td>17.08</td>\n",
              "      <td>5.940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2021-04-14</td>\n",
              "      <td>Argentina Soybeans 3.6% Harvested, Early Yield...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr14_21-Argen...</td>\n",
              "      <td>There were good rains across central and south...</td>\n",
              "      <td>96.92</td>\n",
              "      <td>17.08</td>\n",
              "      <td>5.940</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         Date  ... Cbot_US$\n",
              "32 2021-04-16  ...    5.855\n",
              "33 2021-04-15  ...    5.900\n",
              "34 2021-04-15  ...    5.900\n",
              "35 2021-04-14  ...    5.940\n",
              "36 2021-04-14  ...    5.940\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2DN9Vvh8jOu"
      },
      "source": [
        "## || Criando colunas com o Tarjet de cada valor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrA68rKIVpcn"
      },
      "source": [
        "def Tarjet(x, y):\n",
        "  if x >= y and ((x - y) * 100) / y:\n",
        "    return int(1)\n",
        "  \n",
        "  elif y >= x and ((y - x) * 100) / y:\n",
        "    return 0\n",
        "\n",
        "  else:\n",
        "    return 0\n",
        "  "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19tOW3NOW9p7",
        "outputId": "f2e55da1-db8e-4c88-b361-9ec027cf5545"
      },
      "source": [
        "dados['TARJET_CEPEA_R$'] =[np.nan for x in range(len(dados['Date']))]\n",
        "dados['TARJET_CEPEA_US$'] =[np.nan for x in range(len(dados['Date']))]\n",
        "dados['TARJET_CBOT_US$'] =[np.nan for x in range(len(dados['Date']))]\n",
        "\n",
        "for ini in range(len(dados)):\n",
        "  if ini >= float(0.05):\n",
        "    antes_real = float(dados['Cepea_R$'].iloc[ini -1])\n",
        "    agora_real = float(dados['Cepea_R$'].iloc[ini])\n",
        "   \n",
        "    antes_dolar = float(dados['Cepea_US$'].iloc[ini -1])\n",
        "    agora_dolar = float(dados['Cepea_US$'].iloc[ini])\n",
        "    \n",
        "    antes_cbot = float(dados['Cbot_US$'].iloc[ini -1])\n",
        "    agora_cbot = float(dados['Cbot_US$'].iloc[ini])\n",
        "    \n",
        "    dados['TARJET_CEPEA_R$'].iloc[ini - 1] = Tarjet( antes_real, agora_real)\n",
        "    dados['TARJET_CEPEA_US$'].iloc[ini - 1] = Tarjet(antes_dolar, agora_dolar)\n",
        "    dados['TARJET_CBOT_US$'].iloc[ini - 1] = Tarjet(antes_cbot, agora_cbot)\n",
        "\n",
        "\n",
        "  \n",
        "  \n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:670: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  iloc._setitem_with_indexer(indexer, value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "G7CiLVFhXw5B",
        "outputId": "3c66dacd-9754-4458-c306-34709cb90a5b"
      },
      "source": [
        "dados.head(-1)\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Headlines</th>\n",
              "      <th>Link</th>\n",
              "      <th>News</th>\n",
              "      <th>Cepea_R$</th>\n",
              "      <th>Cepea_US$</th>\n",
              "      <th>Cbot_US$</th>\n",
              "      <th>TARJET_CEPEA_R$</th>\n",
              "      <th>TARJET_CEPEA_US$</th>\n",
              "      <th>TARJET_CBOT_US$</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>2021-04-16</td>\n",
              "      <td>Rating of Safrinha Corn in Parana Declines due...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr16_21-Ratin...</td>\n",
              "      <td>In their latest assessment of the safrinha cor...</td>\n",
              "      <td>97.88</td>\n",
              "      <td>17.52</td>\n",
              "      <td>5.855</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>2021-04-15</td>\n",
              "      <td>Corn-Based Ethanol Accounts for 9% of Brazil's...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr15_21-Corn-...</td>\n",
              "      <td>The production of ethanol from corn continues ...</td>\n",
              "      <td>97.64</td>\n",
              "      <td>17.36</td>\n",
              "      <td>5.900</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>2021-04-15</td>\n",
              "      <td>Port of Paranagua Embarks Record Large Soybean...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr15_21-Port-...</td>\n",
              "      <td>The Port of Paranagua in southern Brazil conti...</td>\n",
              "      <td>97.64</td>\n",
              "      <td>17.36</td>\n",
              "      <td>5.900</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>2021-04-14</td>\n",
              "      <td>IMEA Lowers Mato Grosso's Safrinha Corn Yield</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr14_21-IMEA-...</td>\n",
              "      <td>After the completion of the safrinha corn plan...</td>\n",
              "      <td>96.92</td>\n",
              "      <td>17.08</td>\n",
              "      <td>5.940</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>2021-04-14</td>\n",
              "      <td>Argentina Soybeans 3.6% Harvested, Early Yield...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Apr14_21-Argen...</td>\n",
              "      <td>There were good rains across central and south...</td>\n",
              "      <td>96.92</td>\n",
              "      <td>17.08</td>\n",
              "      <td>5.940</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2734</th>\n",
              "      <td>2014-01-14</td>\n",
              "      <td>Reaction to Last Week's USDA Reports</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan14_14-React...</td>\n",
              "      <td>USDA Crop Summary 2013- The biggest surprise i...</td>\n",
              "      <td>27.35</td>\n",
              "      <td>11.61</td>\n",
              "      <td>4.315</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2735</th>\n",
              "      <td>2014-01-09</td>\n",
              "      <td>Brazilian Corn Acreage Losing out to Higher Pr...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan9_14-Brazii...</td>\n",
              "      <td>Farmers all across Brazil opted for more soybe...</td>\n",
              "      <td>22.51</td>\n",
              "      <td>10.04</td>\n",
              "      <td>4.120</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2736</th>\n",
              "      <td>2014-01-08</td>\n",
              "      <td>Harvest Picks Up in Mato Grosso, Dry Concerns ...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan8_14-Harves...</td>\n",
              "      <td>Farmers in Mato Grosso are starting to harvest...</td>\n",
              "      <td>22.93</td>\n",
              "      <td>10.14</td>\n",
              "      <td>4.170</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2737</th>\n",
              "      <td>2014-01-08</td>\n",
              "      <td>Thousands of Additional Trucks Expected on Bra...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan8_14-Thousd...</td>\n",
              "      <td>The combination of a record large soybean crop...</td>\n",
              "      <td>22.93</td>\n",
              "      <td>10.14</td>\n",
              "      <td>4.170</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2738</th>\n",
              "      <td>2014-01-07</td>\n",
              "      <td>Brazilian Farmers Advised to stay Vigilant abo...</td>\n",
              "      <td>http://soybeansandcorn.com/news/Jan7_14-Brazil...</td>\n",
              "      <td>As farmers in Mato Grosso start to harvest som...</td>\n",
              "      <td>24.46</td>\n",
              "      <td>11.09</td>\n",
              "      <td>4.260</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2297 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           Date  ... TARJET_CBOT_US$\n",
              "32   2021-04-16  ...             0.0\n",
              "33   2021-04-15  ...             0.0\n",
              "34   2021-04-15  ...             0.0\n",
              "35   2021-04-14  ...             0.0\n",
              "36   2021-04-14  ...             1.0\n",
              "...         ...  ...             ...\n",
              "2734 2014-01-14  ...             1.0\n",
              "2735 2014-01-09  ...             0.0\n",
              "2736 2014-01-08  ...             0.0\n",
              "2737 2014-01-08  ...             0.0\n",
              "2738 2014-01-07  ...             0.0\n",
              "\n",
              "[2297 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PFcawYoI7Hff"
      },
      "source": [
        "dados.to_csv('Data_Tarjet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}